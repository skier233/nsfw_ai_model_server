services:
  nsfw-ai-server:
    image: ghcr.io/skier233/nsfw_ai_model_server:nvidia  # NVIDIA build (default)
    # image: ghcr.io/skier233/nsfw_ai_model_server:intel  # Intel Arc build (uncomment to use)
    container_name: nsfw-ai-server
    restart: unless-stopped
    
  # GPU support
  # For Intel GPUs, remove this deploy/resources block and the NVIDIA_* environment variables below.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
    
    ports:
      - "8000:8000"
      - "7483:7483"
    
    volumes:
      # Named volume for media (models, data, etc.)
      - nsfw-ai-data:/media
      # Mount current directory as /app for development/config
      - .:/app:rw

volumes:
  # Use a bind mount so nsfw-ai-data maps to a host directory by default.
  # This points to the project `data/` folder. On most systems Compose
  # exposes ${COMPOSE_PROJECT_DIR}; if your environment doesn't, replace
  # the device value with an absolute path (e.g. C:/path/to/nsfw/data).
  nsfw-ai-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      # Your path to stash files
      device: C:\temp
